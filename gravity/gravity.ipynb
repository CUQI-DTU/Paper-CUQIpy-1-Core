{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import matplotlib\n",
    "import time\n",
    "\n",
    "from cuqi.model import Model\n",
    "from cuqi.distribution import Gaussian, JointDistribution\n",
    "from cuqi.sampler import MH, NUTS\n",
    "from cuqi.geometry import Continuous1D, Discrete\n",
    "\n",
    "import cuqi\n",
    "print(f\"CUQIpy version: {cuqi.__version__}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Case study: user-specified nonlinear model with a gravity anomaly\n",
    "\n",
    "Note. The results will vary slightly from those in the paper due to precision on numerical computations.\n",
    "\n",
    "### 6.1. User-specified model\n",
    "A subsurface body with a density contrast to its surroundings will cause a gravity anomaly. The gravity anomaly field depends on the body's depth, shape, size, and density constrast. \n",
    "\n",
    "We construct a simple example where a spherical body with radius $r=1000$ m, density constrast $\\Delta\\rho = 800$ $\\text{kg}/\\text{m}^3$, and center depth $z=1500$ m causes a gravity anomaly. This could represent a very simple model of iron ore embedded in sedimentary rock. The vertical gravity anomaly signal is then given by the function:\n",
    "\\begin{equation}\n",
    "    F(z, \\Delta\\rho, r, \\xi) = \\frac{4\\pi}{3} G \\left(\\frac{\\Delta\\rho r^3}{z^2}\\right) \\left(\\frac{1}{1+(\\xi/z)^2}\\right)^{3/2}\n",
    "\\end{equation}\n",
    "where $G$ is the gravitational constant and $\\xi$ is the horizontal distance from the surface point above the centre of the body. See the problem illustrated in the figure further down.\n",
    "\n",
    "In the inverse problem we measure the gravity anomaly at $m$ points $\\xi_1, \\dots, \\xi_m$ along a line at the surface, intersecting the center of the body, to obtain data points $y_1,\\dots, y_m$. From this data, we seek to infer $z$, $\\Delta\\rho$ and $r$. Then, the forward problem for one measurement point is given:\n",
    "\\begin{equation}\n",
    "    y_i = F(z,\\Delta\\rho,r,\\xi_i) \\equiv A_i(\\bm{x}) ,\\qquad \\bm{x} = [z,\\Delta\\rho,r]^{T},\n",
    "\\end{equation}\n",
    "and hence the complete nonlinear forward model $\\bm{A}: \\mathbb{R}^3 \\rightarrow \\mathbb{R}^m$ is expressed:\n",
    "\\begin{equation}\n",
    "    \\bm{y} = \\bm{A}(\\bm{x}) =\n",
    "    \\begin{bmatrix} A_1(\\bm{x}) \\\\ \\vdots \\\\ A_m(\\bm{x}) \\end{bmatrix}.\n",
    "\\end{equation}\n",
    "Note that the signal is uniquely determined from $z$ and the product $\\Delta\\rho r^3$, which means $z$ can be inferred from measurements, but $\\Delta\\rho$ and $r$ can not be resolved. \n",
    "\n",
    "To solve the inverse problem with CUQIpy we must define the non-linear forward model. The gravity anomali model is not included in the CUQIpy library, so we define it ourselves and wrap it as a CUQIpy model. Note that we also include the Jacobian of the model. This is nessecary to use gradient based samplers like NUTS later, but can be omitted if gradient based samplers are not needed. We also define the domain and range geometries of the model. The measurements are given by the continuous function (1) and the inferred parameters are different physical quantaties, making CUQIpy's Continuous1D and Discrete geometeries appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measurement grid\n",
    "m = 100 # data dimension\n",
    "xi = np.linspace(-8000, 8000, m)\n",
    "\n",
    "# gravitational constant N m2 kgâˆ’2\n",
    "G = 6.6743e-11 \n",
    "\n",
    "# true parameters defining the subsurface body\n",
    "n = 3 # parameter dimension\n",
    "z_true = 1500 # depth in meters\n",
    "rho_true = 800 # density contrast in kg m-3\n",
    "r_true = 1000 # sphere radius in meters\n",
    "x_true = np.array([z_true, rho_true, r_true], dtype=np.float64)\n",
    "\n",
    "# Forward model with parameter vector as input and measurements as output\n",
    "def forward_gravity(wrt):\n",
    "    z = wrt[0]\n",
    "    rho = wrt[1]\n",
    "    r = wrt[2]\n",
    "    y = 4/3*np.pi*G*(rho*r**3/z**2)*(1/(1+(xi/z)**2))**(3/2)\n",
    "    return y\n",
    "\n",
    "# Jacobian\n",
    "def jac_gravity(wrt):\n",
    "    z = wrt[0]\n",
    "    rho = wrt[1]\n",
    "    r = wrt[2]\n",
    "\n",
    "    dAdz = -4/3*np.pi*G*rho*r**3*z* (2*z**2-xi**2) * 1/(z**2/(xi**2+z**2))**(1/2) * 1/(xi**2+z**2)**3\n",
    "    dAdrho = 4/3*np.pi*G*(r**3/z**2)*(1/(1+(xi/z)**2))**(3/2)\n",
    "    dAdr = 4*np.pi*G*(rho*r**2/z**2)*(1/(1+(xi/z)**2))**(3/2)\n",
    "\n",
    "    J = np.vstack([dAdz, dAdrho, dAdr]).T\n",
    "    return J\n",
    "\n",
    "\n",
    "par_names = [\"z\", \"rho\", \"r\"]\n",
    "domain_geometry = Discrete(par_names)\n",
    "range_geometry = Continuous1D(m)\n",
    "\n",
    "model = Model(forward=forward_gravity, jacobian=jac_gravity, range_geometry=range_geometry, domain_geometry=domain_geometry)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. The Bayesian Problem\n",
    "We define the data distribution and choose an appropriate prior. We will assume that the measurements are corrupted by Gaussian noise with standard deviation $10^{-6}$. And we choose a fairly uninformative prior, where the mean is offset from the true values and the spread is large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_mean = np.array([1550, 850, 950])\n",
    "prior_std = np.array([500, 300, 300])\n",
    "x = Gaussian(prior_mean, sqrtcov = prior_std)\n",
    "\n",
    "data_std = 1e-6\n",
    "y = Gaussian(model(x), sqrtcov=data_std)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve the Bayesian Problem, we simulate a synthetic dataset by taking one realization from the data distribution evaluated at the true model parameters. We also evaluate the model at the true parameters, to obtain the ground truth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalutate the model to get the noise free data\n",
    "y_true = model(x_true)\n",
    "\n",
    "# Sample from the data distribution to get noisy data\n",
    "np.random.seed(0)\n",
    "y_obs = y(x=x_true).sample()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we plot the gravity anomaly and the spherical body causing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=22)          # controls default text sizes\n",
    "plt.rc('axes', labelsize=22)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=18)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=18)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=18)    # fontsize of the legends\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 2, ncols = 1, figsize = (15,7), gridspec_kw={'height_ratios': [1, 1]})\n",
    "circle = plt.Circle((0, -z_true), r_true, color='lightgreen')\n",
    "ax[1].set_axisbelow(True)\n",
    "ax[1].xaxis.grid(color='gray', linestyle='--', linewidth=1)\n",
    "ax[1].yaxis.grid(color='gray', linestyle='--', linewidth=1)\n",
    "ax[1].add_patch(circle)\n",
    "ax[1].plot(np.array([0, r_true/np.sqrt(2)]), np.array([-z_true, -z_true+r_true/np.sqrt(2)]), color = \"blue\", linestyle = \"--\", linewidth = 2)\n",
    "ax[1].plot(np.array([0, 0]), np.array([0, -z_true]), color = \"firebrick\", linestyle = \"--\", linewidth = 2)\n",
    "ax[1].annotate(r\"$r$\", xy=(480,-1500), color = \"blue\")\n",
    "ax[1].annotate(r\"$\\Delta \\rho$\", xy=(-600,-2200), color = \"darkgreen\")\n",
    "ax[1].annotate(r\"$z$\", xy=(-400,-400), color = \"firebrick\")\n",
    "ax[1].set_xlim(xi[0], xi[-1])\n",
    "ax[1].set_ylim(-3000, 0)\n",
    "ax[1].set_yticks([0,-1000,-2000,-3000])\n",
    "ax[1].set_yticklabels([0,1000,2000,3000])\n",
    "ax[1].set_xlabel(r\"$\\xi$ [m]\")\n",
    "ax[1].set_ylabel(r\"depth [m]\")\n",
    "ax[1].set_aspect(\"equal\")\n",
    "\n",
    "ax[0].plot(xi,y_obs*1e5, label = r\"$y^\\mathrm{obs}$\", linewidth = 2)\n",
    "ax[0].plot(xi,y_true*1e5, label = r\"$y^\\mathrm{true}$\", linewidth = 2, linestyle = \"--\")\n",
    "ax[0].set_xticks(np.linspace(-8000, 8000, 9, endpoint = True))\n",
    "ax[0].set_xlim(xi[0], xi[-1])\n",
    "ax[0].set_xticklabels([])\n",
    "ax[0].set_ylabel(\"y [mGal]\")\n",
    "ax[0].legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3. Posterior sampling and analysis\n",
    "\n",
    "From the prior and data distritbutions we form the posterior distribution and print CUQIpy's information about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form the posterior distribution\n",
    "posterior = JointDistribution(x, y)(y=y_obs)\n",
    "print(posterior)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.3.1. Metropolis-Hastings sampling\n",
    "\n",
    "Then we sample the posterior using Metropolis-Hastings with adaptive step size. For that, we define a random seed, a starting point for the sampler and an initial step size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metropolis-Hastings sampling\n",
    "x_init= np.array([1000,2000,1000], dtype=np.float64)\n",
    "scale_init = 100\n",
    "np.random.seed(1000000)\n",
    "MHsampler = MH(posterior, x0 = x_init, scale = scale_init)\n",
    "\n",
    "t_start = time.time()\n",
    "samplesMH = MHsampler.sample_adapt(1000000, 100000)\n",
    "print(\"--- %s seconds ---\" % (time.time() - t_start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace plots\n",
    "plt.figure()\n",
    "traceplot_MH = samplesMH.plot_trace()\n",
    "\n",
    "# Correlation between parameters chains\n",
    "corrcoefMH = np.corrcoef(samplesMH.samples)\n",
    "print(\"Correlation between parameters chains:\")\n",
    "print(pandas.DataFrame(corrcoefMH, par_names, par_names))\n",
    "\n",
    "# Effective sample size\n",
    "ess_MH = samplesMH.compute_ess()\n",
    "print(\"\\nDepth effective sample size: {}\".format(ess_MH[0]))\n",
    "print(\"Density contrast effective sample size: {}\".format(ess_MH[1]))\n",
    "print(\"Radius effective sample size: {}\".format(ess_MH[2]))\n",
    "\n",
    "# 2D marginal of rho and r samples, to show they follow true solution space\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 1)\n",
    "cmap = plt.get_cmap(\"tab10\")\n",
    "ax.plot(samplesMH.samples[1,:], samplesMH.samples[2,:], '.', color = cmap(0), label = \"Samples\")\n",
    "ax.plot(x_init[1], x_init[2], 'x', color = cmap(0), label = 'Starting point')\n",
    "r_grid = np.linspace(300, 2000, 50)\n",
    "ax.plot(rho_true*r_true**3/r_grid**3, r_grid, color = cmap(1), label = 'Analytical true \\nsolution space')\n",
    "ax.plot(rho_true, r_true, 'x', color = cmap(1), label = 'Truth')\n",
    "ax.legend()\n",
    "ax.set_xlim([-5,3000])\n",
    "ax.set_ylim([600,2000])\n",
    "ax.set_xlabel(r\"Density contrast $\\Delta\\rho$ [kg m-3]\")\n",
    "ax.set_ylabel(r\"Radius $r$ [m]\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the 1D marginals (left in traceplots) we see that the posterior samples of the depth parameter constract near the true value and that the chain (right in traceplots) looks well mixed and with high effective sample size (ESS). The chains and 1D marginals for the other two parameters look poor and as if they have not converged and they have extremely low ESS. This is due to strong correlation between the density contrast and radius, which is confirmed by the computed correlation coefficients. From the model we can derive that the relationship between them is given $\\Delta\\rho = (\\Delta\\rho_{true} R_{true}^3)/R^3$. If we plot this curve along the 2D marginal of the samples, we see that they coincide. This means the sampler actually samples from the true solution space even though the chains look poor. However, the sampler moves slowly in the solution space and does not cover much of it. Eventually the samples would represent the entire posterior, but it will take a while. This is expected behaviour since Metropolis-Hastings is not a suitable sampler for highy correlated parameters."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.3.2. NUTS sampling\n",
    "When the parameters are correlated, gradient based samplers are often more efficient for sampling the entire posterior. The gradient information helps the sampler move optimally in the low dimensional subspace. Below we use the NUTS sampler to sample and plot the posterior using the same starting point as for the Metropolis-Hastings sampler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUTS sampling\n",
    "np.random.seed(1000000)\n",
    "NUTSsampler = NUTS(posterior, x0 = x_init)\n",
    "\n",
    "t_start = time.time()\n",
    "samplesNUTS = NUTSsampler.sample_adapt(8000, 100)\n",
    "print(\"--- %s seconds ---\" % (time.time() - t_start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traceplots\n",
    "plt.figure()\n",
    "traceplot_NUTS = samplesNUTS.plot_trace()\n",
    "\n",
    "# Correlation between parameters chains\n",
    "corrcoefNUTS = np.corrcoef(samplesNUTS.samples)\n",
    "print(\"Correlation between parameters chains:\")\n",
    "print(pandas.DataFrame(corrcoefNUTS, par_names, par_names))\n",
    "\n",
    "# Effective sample size\n",
    "ess_NUTS = samplesNUTS.compute_ess()\n",
    "print(\"\\nDepth effective sample size: {}\".format(ess_NUTS[0]))\n",
    "print(\"Density contrast effective sample size: {}\".format(ess_NUTS[1]))\n",
    "print(\"Radius effective sample size: {}\".format(ess_NUTS[2]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 1D marginals and ESS show us that the NUTS sampler has much better chains than the Metropolis-Hastings sampler. Furthermore, NUTS also infers the depth parameter well, but the other two parameters have very wide spreads, which is due to the high correlation between these parameters. \n",
    "Also note, that while Metropolis-Hastings obtain many more samples than NUTS in $\\approx 10$ minutes, the actual effective sample size is higher for NUTS."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.3.3. More informative prior\n",
    "\n",
    "We saw that the density contrast and radius can not be determined uniquely from the data. Our only hope to improve the solution is with a good prior. We formulate a Gaussian prior to imitate the situation where we are quite sure about the density contrast, but not the radius or depth. This might happen if we know we are looking for iron ore in sedimentary rock, but not how much or how deep down.\n",
    "\n",
    "We redefine the prior and posterior and sample with NUTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior\n",
    "prior_mean2 = np.array([1550, 800, 950])\n",
    "prior_std2 = np.array([500, 30, 300])\n",
    "x = Gaussian(prior_mean2 , sqrtcov = prior_std2)\n",
    "\n",
    "# Posterior\n",
    "posterior = JointDistribution(x, y)(y=y_obs)\n",
    "\n",
    "# Sample\n",
    "np.random.seed(1000000)\n",
    "NUTSsampler2 = NUTS(posterior, x0 = x_init)\n",
    "\n",
    "t_start = time.time()\n",
    "samplesNUTS2 = NUTSsampler2.sample_adapt(8000, 100)\n",
    "print(\"--- %s seconds ---\" % (time.time() - t_start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traceplots\n",
    "plt.figure()\n",
    "traceplot_NUTS2 = samplesNUTS2.plot_trace()\n",
    "\n",
    "# Correlation between parameters chains\n",
    "corrcoefNUTS2 = np.corrcoef(samplesNUTS2.samples)\n",
    "print(\"Correlation between parameters chains:\")\n",
    "print(pandas.DataFrame(corrcoefNUTS2, par_names, par_names))\n",
    "\n",
    "# Effective sample size\n",
    "ess2 = samplesNUTS2.compute_ess()\n",
    "print(\"\\nDepth effective sample size: {}\".format(ess2[0]))\n",
    "print(\"Density contrast effective sample size: {}\".format(ess2[1]))\n",
    "print(\"Radius effective sample size: {}\".format(ess2[2]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the more informative prior on the density contrast, leads to the radius being inferred much better. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.3.4. Plot \n",
    "\n",
    "Below we plot the 1D marginals and chains together for all experiments for easy comparison. The plots are taken from CUQIpy's traceplot() functionality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,10))\n",
    "gs = matplotlib.gridspec.GridSpec(5, 3, figure=fig)\n",
    "ax1 = fig.add_subplot(gs[0:2, 0]) # 1D marginal z\n",
    "ax2 = fig.add_subplot(gs[0:2, 1]) # 1D marginal rho\n",
    "ax3 = fig.add_subplot(gs[0:2, 2]) # 1D marginal R\n",
    "ax4 = fig.add_subplot(gs[2, 0]) # z MH chain\n",
    "ax5 = fig.add_subplot(gs[3, 0]) # z NUTS1 chain\n",
    "ax6 = fig.add_subplot(gs[4, 0]) # z NUTS2 chain\n",
    "ax7 = fig.add_subplot(gs[2, 1]) # rho MH chain\n",
    "ax8 = fig.add_subplot(gs[3, 1]) # rho NUTS1 chain\n",
    "ax9 = fig.add_subplot(gs[4, 1]) # rho NUTS2 chain\n",
    "ax10 = fig.add_subplot(gs[2, 2]) # r MH chain\n",
    "ax11 = fig.add_subplot(gs[3, 2]) # r NUTS1 chain\n",
    "ax12 = fig.add_subplot(gs[4, 2]) # r NUTS2 chain\n",
    "\n",
    "\n",
    "cmap = plt.get_cmap(\"tab10\")\n",
    "\n",
    "ticksize = 14\n",
    "legendsize = 16\n",
    "titlesize = 16\n",
    "\n",
    "x_true = np.array([z_true, rho_true, r_true])\n",
    "for i, ax in enumerate([ax1, ax2, ax3]):\n",
    "    tmp_MH = traceplot_MH[i,0].get_lines()[0].get_data()\n",
    "    tmp_NUTS = traceplot_NUTS[i,0].get_lines()[0].get_data()\n",
    "    tmp_NUTS2 = traceplot_NUTS2[i,0].get_lines()[0].get_data()\n",
    "    ax.plot(tmp_MH[0],tmp_MH[1], color = cmap(0), linestyle = \"dashed\", linewidth = 2, label = r\"MH-Pr$1$\")\n",
    "    ax.plot(tmp_NUTS[0],tmp_NUTS[1], color = cmap(2), linestyle = \"dotted\", linewidth = 2, label = r\"NUTS-Pr$1$\")\n",
    "    ax.plot(tmp_NUTS2[0],tmp_NUTS2[1], color = cmap(4), linestyle = \"dashdot\", linewidth = 2, label = r\"NUTS-Pr$2$\")\n",
    "    ax.axvline(x = x_true[i], color = 'k', linestyle = \"solid\", linewidth = 1.5)\n",
    "    ax.axvline(x = prior_mean[i], color = 'k', linestyle = 'solid', linewidth = 1.5)\n",
    "    ax.axvline(x = prior_mean2[i], color = 'k', linestyle = \"solid\", linewidth = 1.5)\n",
    "    ax.set_yticks([])\n",
    "    ax.tick_params(axis='both', which='both', labelsize=ticksize)\n",
    "\n",
    "for i, ax in enumerate([ax4, ax7, ax10]):\n",
    "    tmp_MH = traceplot_MH[i,1].get_lines()[0].get_data()\n",
    "    ax.plot(tmp_MH[0],tmp_MH[1], color = cmap(0), linewidth = 2)\n",
    "    ax.annotate(\"ESS = {}\".format(round(ess_MH[i])), (0.65, 0.8), xycoords=\"axes fraction\", bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha = 0.8, lw=0.5), fontsize = legendsize)\n",
    "    ax.tick_params(axis='both', which='both', labelsize=ticksize)\n",
    "    ax.xaxis.offsetText.set_fontsize(ticksize)\n",
    "\n",
    "for i, ax in enumerate([ax5, ax8, ax11]):\n",
    "    tmp_NUTS = traceplot_NUTS[i,1].get_lines()[0].get_data()\n",
    "    ax.plot(tmp_NUTS[0],tmp_NUTS[1], color = cmap(2), linewidth = 2)\n",
    "    ax.annotate(\"ESS = {}\".format(round(ess_NUTS[i])), (0.65, 0.8), xycoords=\"axes fraction\", bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha = 0.8, lw=0.5), fontsize = legendsize)\n",
    "    ax.tick_params(axis='both', which='both', labelsize=ticksize)\n",
    "\n",
    "for i, ax in enumerate([ax6, ax9, ax12]):\n",
    "    tmp_NUTS2 = traceplot_NUTS2[i,1].get_lines()[0].get_data()\n",
    "    ax.plot(tmp_NUTS2[0],tmp_NUTS2[1], color = cmap(4), linewidth = 2)\n",
    "    ax.annotate(\"ESS = {}\".format(round(ess2[i])), (0.65, 0.8), xycoords=\"axes fraction\", bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha = 0.8, lw=0.5), fontsize = legendsize)\n",
    "    ax.tick_params(axis='both', which='both', labelsize=ticksize)\n",
    "\n",
    "ax1.annotate('Truth', xy =(x_true[0]+1, 0.05), xytext =(x_true[0]+10, 0.045), arrowprops=dict(facecolor='black',arrowstyle=\"simple\"), fontsize = legendsize)\n",
    "ax1.annotate('Pr1/Pr2', xy =(prior_mean[0]-1, 0.04), xytext =(prior_mean[0]-30, 0.035), arrowprops=dict(facecolor='black',arrowstyle=\"simple\"), fontsize = legendsize)\n",
    "\n",
    "ax2.annotate('Truth/Pr2', xy =(x_true[1]-10, 0.013), xytext =(x_true[1]-600, 0.011), arrowprops=dict(facecolor='black',arrowstyle=\"simple\"), fontsize = legendsize)\n",
    "ax2.annotate('Pr1', xy =(prior_mean[1]+10, 0.0105), xytext =(prior_mean[1]+200, 0.01), arrowprops=dict(facecolor='black',arrowstyle=\"simple\"), fontsize = legendsize)\n",
    "\n",
    "ax3.annotate('Truth', xy =(x_true[2]+10, 0.029), xytext =(x_true[2]+120, 0.027), arrowprops=dict(facecolor='black',arrowstyle=\"simple\"), fontsize = legendsize)\n",
    "ax3.annotate('Pr1/Pr2', xy =(prior_mean[2]-10, 0.027), xytext =(prior_mean[2]-230, 0.025), arrowprops=dict(facecolor='black',arrowstyle=\"simple\"), fontsize = legendsize)\n",
    "\n",
    "ax3.legend(fontsize = legendsize, loc = 'center right')\n",
    "\n",
    "ax1.set_title(r\"Depth $z$ [m]\", fontsize = titlesize)\n",
    "ax2.set_title(r\"Density contrast $\\Delta\\rho$ [kg m-3]\", fontsize = titlesize)\n",
    "ax3.set_title(r\"Radius $r$ [m]\", fontsize = titlesize)\n",
    "\n",
    "#ax1.set_ylabel(r\"1D marginals\", fontsize = titlesize)\n",
    "ax4.set_ylabel(r\"MH-Pr1\", fontsize = titlesize)\n",
    "ax5.set_ylabel(r\"NUTS-Pr1\", fontsize = titlesize)\n",
    "ax6.set_ylabel(r\"NUTS-Pr2\", fontsize = titlesize)\n",
    "\n",
    "fig.tight_layout(pad=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del samplesNUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del samplesNUTS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del NUTSsampler2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del MHsampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del samplesMH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13-final"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4358af2097ed0b2858c5e041fb957c9b16381356ca8150ab27f4b2213df16449"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}